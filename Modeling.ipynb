{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8IJS, homo sapience nanobody sequence\n",
    "nb_seq = \"MDVQLVESGGGLVNPGGSLRLSCAASGRTFSSYSMGWFRQAPGKEREFVVAISKGGYKYDAVSLEGRFTISRDNAKNTVYLQINSLRPEDTAVYYCASSRAYGSSRLRLADTYEYWGQGTLVTVSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants for sequence preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_types = \"ACDEFGHIKLMNPQRSTVWY\" # residue types\n",
    "res_to_n = {x: i for i, x in enumerate(res_types)} # create {res : idx} dictionary\n",
    "# atom_types = [\"N\", \"CA\", \"C\", \"O\", \"CB\", \"CG\", \"CD\", \"NE\", \"NZ\", \"OH\"]\n",
    "res_to_num = lambda x: res_to_n[x] if x in res_to_n else len(res_to_n) # res string to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes=21):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape) + [nb_classes])\n",
    "\n",
    "def get_encoding(sequence):\n",
    "    one_hot_amino = get_one_hot(np.array([res_to_num(x) for x in sequence]))\n",
    "    return one_hot_amino\n",
    "\n",
    "# def encoding(sequence):\n",
    "#     nb_classes = len(res_types)\n",
    "#     res_to_num = np.array([res_to_num(x) for x in sequence])\n",
    "\n",
    "#     res = np.eye(nb_classes)[np.array(res_to_num).reshape(-1)]\n",
    "#     encoding = res.reshape(list(targets.shape) + [nb_classes])\n",
    "#     return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([126, 21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = get_encoding(nb_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 126\n",
    "origin = torch.zeros(seq_len, 3) # rigid origin, 3dim\n",
    "rot = torch.eye(3).unsqueeze(0).expand(seq_len,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"MDVQL\"\n",
    "dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_pos(sequence, rel_pos_dim): # node의 상대 위치 반환\n",
    "    # broadcasting에 의해 tensor 크기 맞춰짐 (seq_len, seq_len)\n",
    "    rel_pos = torch.arange(len(sequence)).unsqueeze(-1) - torch.arange(len(sequence)).unsqueeze(0)\n",
    "\n",
    "    # rel_pos_dim 의 두 배 만큼 clamp, 모든 값 양수 되도록 조정\n",
    "    rel_pos = rel_pos.clamp(min=-rel_pos_dim, max=rel_pos_dim) # + rel_pos_dim\n",
    "    return rel_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = get_encoding(seq)\n",
    "sequence_dict = {\"H\", seq}\n",
    "\n",
    "encoding = torch.tensor(get_encoding(sequence_dict), dtype=torch.get_default_dtype())\n",
    "\n",
    "def node_rel_pos(node_features, rel_pos_dim):\n",
    "    relative_positions = (torch.arange(node_features.shape[-2])[None] - torch.arange(node_features.shape[-2])[:, None])\n",
    "    relative_positions = relative_positions.clamp(min=-rel_pos_dim, max=rel_pos_dim) + rel_pos_dim\n",
    "    return relative_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -2, -3, -4],\n",
       "        [ 1,  0, -1, -2, -3],\n",
       "        [ 2,  1,  0, -1, -2],\n",
       "        [ 3,  2,  1,  0, -1],\n",
       "        [ 4,  3,  2,  1,  0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp1 = get_rel_pos(seq, dim)\n",
    "rp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[64, 65, 66, 67, 68],\n",
       "        [63, 64, 65, 66, 67],\n",
       "        [62, 63, 64, 65, 66],\n",
       "        [61, 62, 63, 64, 65],\n",
       "        [60, 61, 62, 63, 64]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp2 = node_rel_pos(node_features, dim)\n",
    "rp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
